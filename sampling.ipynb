{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7916a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from RealESRGAN import RealESRGAN\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from cyclegan_3d.base_model import BaseModel\n",
    "from cyclegan_3d.cycle_gan_model import CycleGANModel\n",
    "from cyclegan_3d.networks3D import define_G, define_D\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",0)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "import pytorch_model_summary as tms\n",
    "import random\n",
    "import cv2\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea218d",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"6\">lschemic</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # ✅ 데이터 설정\n",
    "    'data_path': '../../data/registration_data/',     # Train images path\n",
    "    'val_path': '../../data/registration_data',       # Validation images path\n",
    "    'img_form': 'nii.gz',                                    # 이미지 포맷\n",
    "    'batch_size': 1,\n",
    "    'patch_size': [64,128, 128],                            # 3D 패치 크기 (H, W, D)\n",
    "    'input_nc': 1,                                           # 입력 채널 수\n",
    "    'output_nc': 1,                                          # 출력 채널 수\n",
    "    'resample': False,\n",
    "    'new_resolution': (0.45, 0.45, 0.45),\n",
    "    'min_pixel': 0.1,\n",
    "    'drop_ratio': 0,\n",
    "\n",
    "    # ✅ 모델 구조 설정\n",
    "    'ngf': 64,\n",
    "    'ndf': 64,\n",
    "    'netG': 'Dynet',\n",
    "    'netD': 'n_layers',\n",
    "    'n_layers_D': 3,\n",
    "    'norm': 'instance',\n",
    "    'no_dropout': True,\n",
    "\n",
    "    # ✅ 학습 관련\n",
    "    'isTrain': True,\n",
    "    'model': 'cycle_gan',\n",
    "    'direction': 'AtoB',\n",
    "    'which_direction': 'AtoB',\n",
    "    'phase': 'train',\n",
    "    'gpu_ids': [0],\n",
    "    'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'workers': 4,\n",
    "\n",
    "    'niter': 5000,                  # 학습 유지 epoch 수\n",
    "    'niter_decay': 500,            # 학습률 감소 epoch 수\n",
    "    'epoch_count': 1,\n",
    "    'which_epoch': 'latest',\n",
    "    'continue_train': False,\n",
    "    'lr': 2e-4,\n",
    "    'beta1': 0.5,\n",
    "    'lr_policy': 'lambda',\n",
    "    'lr_decay_iters': 50,\n",
    "    'no_lsgan': False,\n",
    "    'pool_size': 0,\n",
    "    'lambda_A': 10.0,\n",
    "    'lambda_B': 10.0,\n",
    "    'lambda_identity': 0.,\n",
    "\n",
    "    # ✅ 초기화\n",
    "    'init_type': 'normal',\n",
    "    'init_gain': 0.02,\n",
    "\n",
    "    # ✅ 저장/출력\n",
    "    'checkpoints_dir': '../../model/translation/',\n",
    "    'name': '3D_MRI_CT',\n",
    "    'print_freq': 100,\n",
    "    'save_latest_freq': 1000,\n",
    "    'save_epoch_freq':1,\n",
    "    'no_html': True,\n",
    "    'verbose': True,\n",
    "    'suffix': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy_img(tensor):\n",
    "    tensor = tensor.detach().cpu().clamp(0, 1)  # ensure valid range\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "tf=transforms.ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "dwi_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "dwi_sr_model.load_state_dict(torch.load('../../model/ESRGAN/SWI/ckpt_45_checkpoint.pt',map_location=device))\n",
    "ct_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "ct_sr_model.load_state_dict(torch.load('../../model/ESRGAN/CT/ckpt_1000_checkpoint.pt',map_location=device))\n",
    "tr_model = CycleGANModel()\n",
    "from types import SimpleNamespace\n",
    "opt = SimpleNamespace(**params)\n",
    "\n",
    "tr_model.initialize(opt)\n",
    "tr_model.setup(opt)\n",
    "tr_model.device = device\n",
    "tr_model.load_networks(413)\n",
    "data_path='../../result/generator/Ischemic_DWI/'\n",
    "save_path='../../result/generator_sr/'\n",
    "nii_list=glob(data_path+'*.nii.gz')\n",
    "nii_mask_list=[f.replace('/Ischemic_DWI','/Ischemic_mask') for f in nii_list]\n",
    "step=0\n",
    "for i in tqdm(range(len(nii_list))):\n",
    "    nii_img=nib.load(nii_list[i])\n",
    "    nii_img_data=(nii_img.get_fdata()+1.)/2.\n",
    "    nii_img_mask=nib.load(nii_mask_list[i])\n",
    "    nii_img_mask_data=nii_img_mask.get_fdata()\n",
    "    step+=1\n",
    "    folder_name=str(step).zfill(6)\n",
    "    tensor_A=tf(nii_img.get_fdata()).float().to(device)\n",
    "    a=tensor_A.permute(1, 2, 0).unsqueeze(0).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        fake_CT = tr_model.netG_A(a)# Clamp to 0~1 range\n",
    "        fake_CT=(fake_CT+1.)/2\n",
    "        fake_CT=fake_CT.squeeze()\n",
    "    dwi_slide=[]\n",
    "    ct_slide=[]\n",
    "    mask_slide=[]\n",
    "    for j in range(len(nii_img_data)):  # len(nii_img_data)\n",
    "        image=tf(topilimage(nii_img_data[j]).convert('RGB')).float().to(device)\n",
    "        image=image.unsqueeze(0)\n",
    "        ct_image=tf(topilimage(fake_CT[j].squeeze().cpu()).convert('RGB')).float().to(device).unsqueeze(0)\n",
    "        sr_mask=cv2.resize(nii_img_mask_data[j],(256,256))\n",
    "        sr_mask=np.where(sr_mask==2,1,0)*255\n",
    "    \n",
    "        mask_slide.append(sr_mask)\n",
    "        with torch.no_grad():\n",
    "            sr = dwi_sr_model(image)\n",
    "            sr = sr.squeeze(0).cpu().numpy()\n",
    "            sr_ct=ct_sr_model(ct_image)\n",
    "            sr_ct = sr_ct.squeeze(0).cpu().numpy()\n",
    "            dwi_slide.append(sr[0])\n",
    "            ct_slide.append(sr_ct[0])\n",
    "        \n",
    "    dwi_slide=np.array(dwi_slide)\n",
    "    # min-max 정규화\n",
    "    dwi_slide = (dwi_slide - dwi_slide.min()) / (dwi_slide.max() - dwi_slide.min())\n",
    "    dwi_slide=dwi_slide*255\n",
    "    dwi_slide = dwi_slide.astype(np.uint8)\n",
    "    ct_slide=np.array(ct_slide)\n",
    "\n",
    "    ct_slide = (ct_slide - ct_slide.min()) / (ct_slide.max() - ct_slide.min())\n",
    "    ct_slide=ct_slide*255\n",
    "    ct_slide = ct_slide.astype(np.uint8)\n",
    "    mask_slide=np.array(mask_slide).astype(np.uint8)\n",
    "    create_dir(save_path+'Ischemic_DWI/'+folder_name)\n",
    "    create_dir(save_path+'Ischemic_CT/'+folder_name)\n",
    "    create_dir(save_path+'Ischemic_mask/'+folder_name)\n",
    "    for j in range(len(nii_img_data)):\n",
    "        Image.fromarray(dwi_slide[j]).save(save_path+'Ischemic_DWI/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(ct_slide[j]).save(save_path+'Ischemic_CT/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(mask_slide[j]).save(save_path+'Ischemic_mask/'+folder_name+'/'+str(j).zfill(6)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e2e90",
   "metadata": {},
   "source": [
    "<font size=\"6\">Normal</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy_img(tensor):\n",
    "    tensor = tensor.detach().cpu().clamp(0, 1)  # ensure valid range\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "tf=transforms.ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "dwi_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "dwi_sr_model.load_state_dict(torch.load('../../model/ESRGAN/SWI/ckpt_45_checkpoint.pt',map_location=device))\n",
    "ct_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "ct_sr_model.load_state_dict(torch.load('../../model/ESRGAN/CT/ckpt_1000_checkpoint.pt',map_location=device))\n",
    "\n",
    "from types import SimpleNamespace\n",
    "opt = SimpleNamespace(**params)\n",
    "# tr_model = CycleGANModel()\n",
    "# tr_model.initialize(opt)\n",
    "# tr_model.setup(opt)\n",
    "# tr_model.device = device\n",
    "# tr_model .load_networks(153)\n",
    "data_path='../../result/generator/Normal_DWI/'\n",
    "save_path='../../result/generator_sr/'\n",
    "nii_list=glob(data_path+'*.nii.gz')\n",
    "nii_mask_list=[f.replace('/Normal_DWI','/Normal_mask') for f in nii_list]\n",
    "step=0\n",
    "for i in tqdm(range(len(nii_list))):\n",
    "    nii_img=nib.load(nii_list[i])\n",
    "    nii_img_data=(nii_img.get_fdata()+1.)/2.\n",
    "    nii_img_mask=nib.load(nii_mask_list[i])\n",
    "    nii_img_mask_data=nii_img_mask.get_fdata()\n",
    "    step+=1\n",
    "    folder_name=str(step).zfill(6)\n",
    "    tensor_A=tf(nii_img.get_fdata()).float().to(device)\n",
    "    a=tensor_A .permute(1, 0, 2).unsqueeze(0).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        fake_CT = tr_model.netG_A(a)# Clamp to 0~1 range\n",
    "        fake_CT=torch.where(fake_CT<-1,-1,fake_CT)\n",
    "        fake_CT=torch.where(fake_CT>1,1.,fake_CT)\n",
    "        fake_CT=(fake_CT+1.)/2\n",
    "        fake_CT=fake_CT.squeeze()\n",
    "    dwi_slide=[]\n",
    "    ct_slide=[]\n",
    "    mask_slide=[]\n",
    "    for j in range(len(nii_img_data)):  # len(nii_img_data)\n",
    "        image=tf(topilimage(nii_img_data[j]).convert('RGB')).float().to(device)\n",
    "        image=image.unsqueeze(0)\n",
    "        ct_image=tf(topilimage(fake_CT[j].squeeze().cpu()).convert('RGB')).float().to(device).unsqueeze(0)\n",
    "        sr_mask=cv2.resize(nii_img_mask_data[j],(256,256))\n",
    "        sr_mask=np.where(sr_mask==2,1,0)*255\n",
    "    \n",
    "        mask_slide.append(sr_mask)\n",
    "        with torch.no_grad():\n",
    "            sr = dwi_sr_model(image)\n",
    "            sr = sr.squeeze(0).cpu().numpy()\n",
    "            sr_ct=ct_sr_model(ct_image)\n",
    "            sr_ct = sr_ct.squeeze(0).cpu().numpy()\n",
    "            dwi_slide.append(sr[0])\n",
    "            ct_slide.append(sr_ct[0])\n",
    "        \n",
    "    dwi_slide=np.array(dwi_slide)\n",
    "    # min-max 정규화\n",
    "    dwi_slide = (dwi_slide - dwi_slide.min()) / (dwi_slide.max() - dwi_slide.min())\n",
    "    dwi_slide=dwi_slide*255\n",
    "    dwi_slide = dwi_slide.astype(np.uint8)\n",
    "    ct_slide=np.array(ct_slide)\n",
    "\n",
    "    ct_slide = (ct_slide - ct_slide.min()) / (ct_slide.max() - ct_slide.min())\n",
    "    ct_slide=ct_slide*255\n",
    "    ct_slide = ct_slide.astype(np.uint8)\n",
    "    mask_slide=np.array(mask_slide).astype(np.uint8)\n",
    "    create_dir(save_path+'Normal_DWI/'+folder_name)\n",
    "    create_dir(save_path+'Normal_CT/'+folder_name)\n",
    "    create_dir(save_path+'Normal_mask/'+folder_name)\n",
    "    for j in range(len(nii_img_data)):\n",
    "        Image.fromarray(dwi_slide[j]).save(save_path+'Normal_DWI/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(ct_slide[j]).save(save_path+'Normal_CT/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(mask_slide[j]).save(save_path+'Normal_mask/'+folder_name+'/'+str(j).zfill(6)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c295c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(tr_model.netG_A, input_size=(1, 1, 64, 128, 128), device=opt.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
