{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce51de9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 09:22:07.810756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-10 09:22:07.825393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-10 09:22:07.830047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-10 09:22:07.844557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-10 09:22:08.586993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APEX: OFF\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "from diffusion_model.trainer import GaussianDiffusion, num_to_groups\n",
    "from diffusion_model.trainer import GaussianDiffusion, Trainer\n",
    "from diffusion_model.unet import create_model\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from utils.dtypes import LabelEnum\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3286348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:1\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exportfolder ='../../../result/generator/Normal_SWI'\n",
    "inputfolder = '../../../data/stroke_swi_nii/Skyra&Verio/masks'\n",
    "input_size = 128\n",
    "depth_size = 64\n",
    "batchsize = 8\n",
    "weightfile = '../../../model/med_ddpm/swi/model-4520.pt'\n",
    "num_channels = 64\n",
    "num_res_blocks = 1\n",
    "num_samples = 1\n",
    "in_channels =3\n",
    "out_channels = 1\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: \", device)\n",
    "\n",
    "mask_list = sorted(glob.glob(f\"{inputfolder}/*.nii.gz\"))\n",
    "print(len(mask_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e770056b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def resize_img_4d(input_img):\n",
    "    d, h, w, c = input_img.shape  # Axial 기준: (D, H, W, C)\n",
    "    result_img = np.zeros((depth_size, input_size, input_size, in_channels - 1))  # (D, H, W, C)\n",
    "\n",
    "    if d != depth_size or h != input_size or w != input_size:\n",
    "        for ch in range(c):\n",
    "            buff = input_img[..., ch]  # (D, H, W)\n",
    "            img = tio.ScalarImage(tensor=buff[np.newaxis, ...])  # (1, D, H, W)\n",
    "            cop = tio.Resize((depth_size, input_size, input_size))\n",
    "            img = np.asarray(cop(img))[0]  # (D, H, W)\n",
    "            result_img[..., ch] = img\n",
    "        return result_img\n",
    "    else:\n",
    "        return input_img\n",
    "\n",
    "\n",
    "def label2masks(masked_img):\n",
    "    result_img = np.zeros(masked_img.shape + (in_channels-1,))\n",
    "    result_img[masked_img==LabelEnum.BRAINAREA.value, 0] = 1\n",
    "    result_img[masked_img==LabelEnum.TUMORAREA.value, 1] = 1\n",
    "    return result_img\n",
    "\n",
    "\n",
    "input_transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.permute(3, 0, 1, 2)),\n",
    "    Lambda(lambda t: t.unsqueeze(0))\n",
    "])\n",
    "\n",
    "model = create_model(input_size, num_channels, num_res_blocks, in_channels=in_channels, out_channels=out_channels).to(device)\n",
    "\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = input_size,\n",
    "    depth_size = depth_size,\n",
    "    timesteps = 250,   # number of steps\n",
    "    loss_type = 'L1', \n",
    "    with_condition=True,\n",
    ").to(device)\n",
    "diffusion.load_state_dict(torch.load(weightfile,map_location=device))\n",
    "print(\"Model Loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a9b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT:  315\n",
      "LEFT:  314\n",
      "LEFT:  313\n",
      "LEFT:  312\n",
      "LEFT:  311\n",
      "LEFT:  310\n",
      "LEFT:  309\n",
      "LEFT:  308\n",
      "LEFT:  307\n",
      "LEFT:  306\n",
      "LEFT:  305\n",
      "LEFT:  304\n",
      "LEFT:  303\n",
      "LEFT:  302\n",
      "LEFT:  301\n",
      "LEFT:  300\n",
      "LEFT:  299\n",
      "LEFT:  298\n",
      "LEFT:  297\n",
      "LEFT:  296\n",
      "LEFT:  295\n",
      "LEFT:  294\n",
      "LEFT:  293\n",
      "LEFT:  292\n",
      "LEFT:  291\n",
      "LEFT:  290\n",
      "LEFT:  289\n",
      "LEFT:  288\n",
      "LEFT:  287\n",
      "LEFT:  286\n",
      "LEFT:  285\n",
      "LEFT:  284\n",
      "LEFT:  283\n",
      "LEFT:  282\n",
      "LEFT:  281\n",
      "LEFT:  280\n",
      "LEFT:  279\n",
      "LEFT:  278\n",
      "LEFT:  277\n",
      "LEFT:  276\n",
      "LEFT:  275\n",
      "LEFT:  274\n",
      "LEFT:  273\n",
      "LEFT:  272\n",
      "LEFT:  271\n",
      "LEFT:  270\n",
      "LEFT:  269\n",
      "LEFT:  268\n",
      "LEFT:  267\n",
      "LEFT:  266\n",
      "LEFT:  265\n",
      "LEFT:  264\n",
      "LEFT:  263\n",
      "LEFT:  262\n",
      "LEFT:  261\n",
      "LEFT:  260\n",
      "LEFT:  259\n",
      "LEFT:  258\n",
      "LEFT:  257\n",
      "LEFT:  256\n",
      "LEFT:  255\n",
      "LEFT:  254\n",
      "LEFT:  253\n",
      "LEFT:  252\n",
      "LEFT:  251\n",
      "LEFT:  250\n",
      "LEFT:  249\n",
      "LEFT:  248\n",
      "LEFT:  247\n",
      "LEFT:  246\n",
      "LEFT:  245\n",
      "LEFT:  244\n",
      "LEFT:  243\n",
      "LEFT:  242\n",
      "LEFT:  241\n",
      "LEFT:  240\n",
      "LEFT:  239\n",
      "LEFT:  238\n",
      "LEFT:  237\n",
      "LEFT:  236\n",
      "LEFT:  235\n",
      "LEFT:  234\n",
      "LEFT:  233\n",
      "LEFT:  232\n",
      "LEFT:  231\n",
      "LEFT:  230\n",
      "LEFT:  229\n",
      "LEFT:  228\n",
      "LEFT:  227\n",
      "LEFT:  226\n",
      "LEFT:  225\n",
      "LEFT:  224\n",
      "LEFT:  223\n",
      "LEFT:  222\n",
      "LEFT:  221\n",
      "LEFT:  220\n",
      "LEFT:  219\n",
      "LEFT:  218\n",
      "LEFT:  217\n",
      "LEFT:  216\n",
      "LEFT:  215\n",
      "LEFT:  214\n",
      "LEFT:  213\n",
      "LEFT:  212\n",
      "LEFT:  211\n",
      "LEFT:  210\n",
      "LEFT:  209\n",
      "LEFT:  208\n",
      "LEFT:  207\n",
      "LEFT:  206\n",
      "LEFT:  205\n",
      "LEFT:  204\n",
      "LEFT:  203\n",
      "LEFT:  202\n",
      "LEFT:  201\n",
      "LEFT:  200\n",
      "LEFT:  199\n",
      "LEFT:  198\n",
      "LEFT:  197\n",
      "LEFT:  196\n",
      "LEFT:  195\n",
      "LEFT:  194\n",
      "LEFT:  193\n",
      "LEFT:  192\n",
      "LEFT:  191\n",
      "LEFT:  190\n",
      "LEFT:  189\n",
      "LEFT:  188\n",
      "LEFT:  187\n",
      "LEFT:  186\n",
      "LEFT:  185\n",
      "LEFT:  184\n",
      "LEFT:  183\n",
      "LEFT:  182\n",
      "LEFT:  181\n",
      "LEFT:  180\n",
      "LEFT:  179\n",
      "LEFT:  178\n",
      "LEFT:  177\n",
      "LEFT:  176\n",
      "LEFT:  175\n",
      "LEFT:  174\n",
      "LEFT:  173\n",
      "LEFT:  172\n",
      "LEFT:  171\n",
      "LEFT:  170\n",
      "LEFT:  169\n",
      "LEFT:  168\n",
      "LEFT:  167\n",
      "LEFT:  166\n",
      "LEFT:  165\n",
      "LEFT:  164\n",
      "LEFT:  163\n",
      "LEFT:  162\n",
      "LEFT:  161\n",
      "LEFT:  160\n",
      "LEFT:  159\n",
      "LEFT:  158\n",
      "LEFT:  157\n",
      "LEFT:  156\n",
      "LEFT:  155\n",
      "LEFT:  154\n",
      "LEFT:  153\n",
      "LEFT:  152\n",
      "LEFT:  151\n",
      "LEFT:  150\n",
      "LEFT:  149\n",
      "LEFT:  148\n",
      "LEFT:  147\n",
      "LEFT:  146\n",
      "LEFT:  145\n",
      "LEFT:  144\n",
      "LEFT:  143\n",
      "LEFT:  142\n",
      "LEFT:  141\n",
      "LEFT:  140\n",
      "LEFT:  139\n",
      "LEFT:  138\n",
      "LEFT:  137\n",
      "LEFT:  136\n",
      "LEFT:  135\n",
      "LEFT:  134\n",
      "LEFT:  133\n",
      "LEFT:  132\n",
      "LEFT:  131\n",
      "LEFT:  130\n",
      "LEFT:  129\n",
      "LEFT:  128\n",
      "LEFT:  127\n",
      "LEFT:  126\n",
      "LEFT:  125\n",
      "LEFT:  124\n",
      "LEFT:  123\n",
      "LEFT:  122\n",
      "LEFT:  121\n",
      "LEFT:  120\n",
      "LEFT:  119\n",
      "LEFT:  118\n",
      "LEFT:  117\n",
      "LEFT:  116\n",
      "LEFT:  115\n",
      "LEFT:  114\n",
      "LEFT:  113\n",
      "LEFT:  112\n",
      "LEFT:  111\n",
      "LEFT:  110\n",
      "LEFT:  109\n",
      "LEFT:  108\n",
      "LEFT:  107\n",
      "LEFT:  106\n",
      "LEFT:  105\n",
      "LEFT:  104\n",
      "LEFT:  103\n",
      "LEFT:  102\n",
      "LEFT:  101\n",
      "LEFT:  100\n",
      "LEFT:  99\n",
      "LEFT:  98\n",
      "LEFT:  97\n",
      "LEFT:  96\n",
      "LEFT:  95\n",
      "LEFT:  94\n",
      "LEFT:  93\n",
      "LEFT:  92\n",
      "LEFT:  91\n",
      "LEFT:  90\n",
      "LEFT:  89\n",
      "LEFT:  88\n",
      "LEFT:  87\n",
      "LEFT:  86\n",
      "LEFT:  85\n",
      "LEFT:  84\n",
      "LEFT:  83\n",
      "LEFT:  82\n",
      "LEFT:  81\n",
      "LEFT:  80\n",
      "LEFT:  79\n",
      "LEFT:  78\n",
      "LEFT:  77\n",
      "LEFT:  76\n",
      "LEFT:  75\n",
      "LEFT:  74\n",
      "LEFT:  73\n",
      "LEFT:  72\n",
      "LEFT:  71\n",
      "LEFT:  70\n",
      "LEFT:  69\n",
      "LEFT:  68\n",
      "LEFT:  67\n",
      "LEFT:  66\n",
      "LEFT:  65\n",
      "LEFT:  64\n",
      "LEFT:  63\n",
      "LEFT:  62\n",
      "LEFT:  61\n",
      "LEFT:  60\n",
      "LEFT:  59\n",
      "LEFT:  58\n",
      "LEFT:  57\n",
      "LEFT:  56\n",
      "LEFT:  55\n",
      "LEFT:  54\n",
      "LEFT:  53\n",
      "LEFT:  52\n",
      "LEFT:  51\n",
      "LEFT:  50\n",
      "LEFT:  49\n",
      "LEFT:  48\n",
      "LEFT:  47\n",
      "LEFT:  46\n",
      "LEFT:  45\n",
      "LEFT:  44\n",
      "LEFT:  43\n",
      "LEFT:  42\n",
      "LEFT:  41\n",
      "LEFT:  40\n",
      "LEFT:  39\n",
      "LEFT:  38\n",
      "LEFT:  37\n",
      "LEFT:  36\n",
      "LEFT:  35\n",
      "LEFT:  34\n",
      "LEFT:  33\n",
      "LEFT:  32\n",
      "LEFT:  31\n",
      "LEFT:  30\n",
      "LEFT:  29\n",
      "LEFT:  28\n",
      "LEFT:  27\n",
      "LEFT:  26\n",
      "LEFT:  25\n",
      "LEFT:  24\n",
      "LEFT:  23\n",
      "LEFT:  22\n",
      "LEFT:  21\n",
      "LEFT:  20\n",
      "LEFT:  19\n",
      "LEFT:  18\n",
      "LEFT:  17\n",
      "LEFT:  16\n",
      "LEFT:  15\n",
      "LEFT:  14\n",
      "LEFT:  13\n",
      "LEFT:  12\n",
      "LEFT:  11\n",
      "LEFT:  10\n",
      "LEFT:  9\n",
      "LEFT:  8\n",
      "LEFT:  7\n",
      "LEFT:  6\n",
      "LEFT:  5\n",
      "LEFT:  4\n",
      "LEFT:  3\n",
      "LEFT:  2\n",
      "LEFT:  1\n",
      "LEFT:  0\n"
     ]
    }
   ],
   "source": [
    "max_file_size_kb = 3450\n",
    "max_retry = 10\n",
    "img_dir = exportfolder\n",
    "for k, inputfile in enumerate(mask_list):\n",
    "    left = len(mask_list) - (k + 1)\n",
    "    print(\"LEFT: \", left)\n",
    "\n",
    "    ref = nib.load(inputfile)\n",
    "    msk_name = inputfile.split('/')[-1]\n",
    "    refImg = ref.get_fdata()\n",
    "    img = label2masks(refImg)\n",
    "    img = resize_img_4d(img)\n",
    "    input_tensor = input_transform(img)\n",
    "    condition_tensor = input_tensor.to(device)\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        saved_count = 0\n",
    "        retry = 0\n",
    "        file_saved = False\n",
    "        generated = diffusion.sample(batch_size=batchsize, condition_tensors=condition_tensor.repeat(batchsize, 1, 1, 1, 1))\n",
    "        generated = generated.unsqueeze(1).cpu().numpy()  # (B, 1, D, H, W)\n",
    "\n",
    "        for b in range(batchsize):\n",
    "            sampleImage = generated[b][0]  # shape: (D, H, W)\n",
    "            sampleImage = sampleImage.reshape(refImg.shape)\n",
    "\n",
    "            # 저장 경로 생성\n",
    "            out_name = f\"{b}_{msk_name}\"\n",
    "            nifti_path = os.path.join(img_dir, out_name)\n",
    "            nifti_img = nib.Nifti1Image(sampleImage, affine=ref.affine)\n",
    "            nib.save(nifti_img, nifti_path)\n",
    "            file_size_kb = os.path.getsize(nifti_path) / 1024\n",
    "            # if file_size_kb <= max_file_size_kb:\n",
    "            #     file_saved = True\n",
    "            #     saved_count += 1\n",
    "            #     break\n",
    "            # else:\n",
    "            #     os.remove(nifti_path)  # 너무 크면 삭제하고 재시도\n",
    "            #     continue\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
