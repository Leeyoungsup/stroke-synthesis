{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ff1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomCrop, Compose, ToPILImage, Resize, ToTensor, Lambda\n",
    "from med_ddpm.diffusion_model.trainer import GaussianDiffusion, Trainer\n",
    "from med_ddpm.diffusion_model.unet import create_model\n",
    "import argparse\n",
    "import torch\n",
    "import os \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"with_condition\": True,\n",
    "    \"inputfolder\": \"../../data/registration_data/registration_DWI/\",\n",
    "    \"targetfolder\": \"../../data/registration_data/CT/\",\n",
    "    \"batchsize\": 1,\n",
    "    \"epochs\": 10000,\n",
    "    \"input_size\": 128,\n",
    "    \"depth_size\": 64,\n",
    "    \"num_channels\": 64,\n",
    "    \"num_res_blocks\": 1,\n",
    "    \"timesteps\": 250,\n",
    "    \"save_and_sample_every\": 10,\n",
    "    \"model_save_path\": \"../../model/med_ddpm_translation/dwi2ct/\",\n",
    "    \"resume_weight\": \"../../model/med_ddpm/mri/model-17.pt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688833e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: (t * 2) - 1),\n",
    "    Lambda(lambda t: t.unsqueeze(0))\n",
    "])\n",
    "class NiftiPairImageGenerator(Dataset):\n",
    "    def __init__(self,\n",
    "            input_image,\n",
    "            target_image,\n",
    "            input_size: int,\n",
    "            depth_size: int,\n",
    "            input_channel: int = 3,\n",
    "            target_transform=None,\n",
    "            full_channel_mask=False,\n",
    "            combine_output=False,\n",
    "            transform=None,\n",
    "        ):\n",
    "\n",
    "        self.input_image = input_image\n",
    "        self.target_image = target_image\n",
    "        self.input_size = input_size\n",
    "        self.depth_size = depth_size\n",
    "        self.input_channel = input_channel\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.target_transform = target_transform\n",
    "        self.full_channel_mask = full_channel_mask\n",
    "        self.combine_output = combine_output\n",
    "\n",
    "\n",
    "    def plot(self, index, n_slice=30):\n",
    "        data = self[index]\n",
    "        input_img = data['input']\n",
    "        target_img = data['target']\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(input_img[n_slice,:, :])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(target_img[n_slice,:, :])\n",
    "        plt.show()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_img = self.input_image[index].unsqueeze(0)\n",
    "        target_img = self.target_image[index].unsqueeze(0)\n",
    "      \n",
    "\n",
    "        if self.combine_output:\n",
    "            return torch.cat([target_img, input_img], 0)\n",
    "\n",
    "        return {'input':input_img, 'target':target_img}\n",
    "\n",
    "def resize_img(img):\n",
    "    d, h, w = img.shape\n",
    "    target_d = params['depth_size']\n",
    "    target_h = params['input_size']\n",
    "    target_w = params['input_size']\n",
    "\n",
    "    img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)\n",
    "\n",
    "    # 현재 사이즈\n",
    "    curr_d, curr_h, curr_w = img_tensor.shape[2:]\n",
    "\n",
    "    \n",
    "    img_tensor = F.interpolate(img_tensor, size=(target_d, target_h, target_w), mode='nearest')\n",
    "\n",
    "    return img_tensor.squeeze(0).squeeze(0).numpy()  # (D, H, W)\n",
    "input_list=glob(params['inputfolder']+\"*.nii.gz\")\n",
    "target_list=[f.replace(params['inputfolder'], params['targetfolder']) for f in input_list]\n",
    "input_images=torch.zeros((len(input_list), params['depth_size'], params['input_size'], params['input_size']))\n",
    "target_images=torch.zeros((len(target_list), params['depth_size'], params['input_size'], params['input_size']))\n",
    "for i in tqdm(range(len(input_list))):\n",
    "    input_img = nib.load(input_list[i]).get_fdata()/2.\n",
    "    target_img = nib.load(target_list[i]).get_fdata()/2.\n",
    "    input_images[i] =transform(resize_img(input_img))\n",
    "    target_images[i] = transform(resize_img(target_img))\n",
    "    \n",
    "dataset = NiftiPairImageGenerator(\n",
    "        input_images,\n",
    "        target_images,\n",
    "        input_size=params['input_size'],\n",
    "        depth_size=params['depth_size'],\n",
    "        target_transform=transform,\n",
    "        full_channel_mask=True\n",
    "    )\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "dataloader= DataLoader(dataset, batch_size = params['batchsize'], shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9142cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=2\n",
    "out_channels=1\n",
    "model = create_model(params[\"input_size\"], params[\"num_channels\"], params[\"num_res_blocks\"], in_channels=in_channels, out_channels=out_channels).to(device)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = params[\"input_size\"],\n",
    "    depth_size = params[\"depth_size\"],\n",
    "    timesteps = params[\"timesteps\"],   # number of steps\n",
    "    loss_type = 'l1',    # L1 or L2\n",
    "    with_condition=params[\"with_condition\"],\n",
    "    channels=out_channels\n",
    ").to(device)\n",
    "# diffusion.load_state_dict(torch.load('../../model/med_ddpm_translation/dwi2ct/model-1380.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced44c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(diffusion, epoch, save_path, sample_shape, device, condition_tensors=None):\n",
    "    diffusion.eval()\n",
    "\n",
    "    # 샘플 생성\n",
    "    samples = diffusion.sample(batch_size=sample_shape[0], condition_tensors=condition_tensors)\n",
    "    samples = samples.cpu().numpy()  # (B, C, D, H, W)\n",
    "\n",
    "    # condition도 numpy로 변환 (B, C, D, H, W)\n",
    "    if condition_tensors is not None:\n",
    "        condition_np = condition_tensors.detach().cpu().numpy()\n",
    "    else:\n",
    "        condition_np = None\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    for i in range(samples.shape[0]):\n",
    "        gen_img = samples[i, 0]  # (D, H, W)\n",
    "        nifti_gen = nib.Nifti1Image(gen_img, affine=np.eye(4))\n",
    "        nib.save(nifti_gen, os.path.join(save_path, f'gen_epoch{epoch}.nii.gz'))\n",
    "\n",
    "        if condition_np is not None:\n",
    "            cond_img = condition_np[i, 0]  # (D, H, W)\n",
    "            nifti_cond = nib.Nifti1Image(cond_img, affine=np.eye(4))\n",
    "            nib.save(nifti_cond, os.path.join(save_path, f'cond_epoch{epoch}.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 767/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0429]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 768/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0486]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 769/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0432]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 770/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 771/10000: 100%|██████████| 495/495 [01:14<00:00,  6.66it/s, loss=0.0467]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 772/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0454]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 773/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0422]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 774/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0417]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 775/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0447]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 776/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0455]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 777/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0423]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 778/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0451]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 779/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0465]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 780/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.044] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 781/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0467]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 782/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0428]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 783/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0419]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 784/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0501]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 785/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0452]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 786/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0469]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 787/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0434]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 788/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0439]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 789/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0416]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 790/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 791/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0435]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 792/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0417]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 793/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0433]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 794/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0428]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 795/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0436]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 796/10000: 100%|██████████| 495/495 [01:14<00:00,  6.69it/s, loss=0.0443]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.49it/s]\n",
      "Epoch 797/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0439]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 798/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0439]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 799/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0424]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 800/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 801/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.04]  \n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 802/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.044] \n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 803/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0457]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 804/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0424]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 805/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0464]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 806/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0454]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 807/10000: 100%|██████████| 495/495 [01:14<00:00,  6.69it/s, loss=0.044] \n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 808/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0472]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 809/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0438]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 810/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.049] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 811/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0475]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 812/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0418]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 813/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0432]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 814/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0432]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.49it/s]\n",
      "Epoch 815/10000: 100%|██████████| 495/495 [01:14<00:00,  6.67it/s, loss=0.0465]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 816/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0457]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 817/10000: 100%|██████████| 495/495 [01:13<00:00,  6.69it/s, loss=0.0424]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.48it/s]\n",
      "Epoch 818/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0434]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 819/10000: 100%|██████████| 495/495 [01:14<00:00,  6.69it/s, loss=0.0392]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 820/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at epoch 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 821/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0417]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 822/10000: 100%|██████████| 495/495 [01:14<00:00,  6.69it/s, loss=0.0406]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.50it/s]\n",
      "Epoch 823/10000: 100%|██████████| 495/495 [01:14<00:00,  6.68it/s, loss=0.0478]\n",
      "sampling loop time step: 100%|██████████| 250/250 [00:12<00:00, 20.51it/s]\n",
      "Epoch 824/10000:  83%|████████▎ | 410/495 [01:01<00:12,  6.71it/s, loss=0.0426]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(diffusion.parameters(), lr=2e-5)\n",
    "num_epochs = params['epochs']\n",
    "save_every = params['save_and_sample_every']\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss=0\n",
    "    diffusion.train()\n",
    "    with tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        for step, data in enumerate(pbar):\n",
    "            if params['with_condition']:\n",
    "                input_tensors = data['input'].to(device)    # condition\n",
    "                target_tensors = data['target'].to(device)  # target\n",
    "                loss = diffusion(target_tensors, condition_tensors=input_tensors)\n",
    "            else:\n",
    "                input_tensors = data.to(device)\n",
    "                loss = diffusion(input_tensors)\n",
    "\n",
    "            loss = loss.sum() / params['batchsize']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            sum_loss += loss.item()\n",
    "            pbar.set_postfix(loss=sum_loss/(step+1))\n",
    "\n",
    "    # 모델 저장\n",
    "    if (epoch + 1) % save_every == 0 or (epoch + 1) == num_epochs:\n",
    "        os.makedirs(params[\"model_save_path\"], exist_ok=True)\n",
    "        torch.save(diffusion.state_dict(), os.path.join(params[\"model_save_path\"], f\"model-{epoch+1}.pt\"))\n",
    "        print(f\"✅ Model saved at epoch {epoch+1}\")\n",
    "        \n",
    "    condition_example = None\n",
    "    if params[\"with_condition\"]:\n",
    "        data_example = next(iter(dataloader))\n",
    "        condition_example = data_example['input'].to(device)[:1]  # 1개만\n",
    "    save_sample(\n",
    "        diffusion=diffusion,\n",
    "        epoch=epoch + 1,\n",
    "        save_path=os.path.join(params[\"model_save_path\"], \"samples\"),\n",
    "        sample_shape=(1, diffusion.channels, diffusion.depth_size, diffusion.image_size, diffusion.image_size),\n",
    "        device=device,\n",
    "        condition_tensors=condition_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b30a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
