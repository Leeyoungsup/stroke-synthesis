{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7916a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 17:36:57.430868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-28 17:36:57.446376: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-28 17:36:57.450721: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-28 17:36:57.463791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-28 17:36:58.164246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APEX: OFF\n",
      "GPUs used:\t8\n",
      "Device:\t\tcuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from RealESRGAN import RealESRGAN\n",
    "import os\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torch import Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from glob import glob\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import random\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from cyclegan_3d.base_model import BaseModel\n",
    "from cyclegan_3d.cycle_gan_model import CycleGANModel\n",
    "from cyclegan_3d.networks3D import define_G, define_D\n",
    "#-*- coding:utf-8 -*-\n",
    "from med_ddpm.diffusion_model.trainer import GaussianDiffusion, num_to_groups\n",
    "from med_ddpm.diffusion_model.trainer import GaussianDiffusion, Trainer\n",
    "from med_ddpm.diffusion_model.unet import create_model\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from med_ddpm.utils.dtypes import LabelEnum\n",
    "import torchio as tio\n",
    "\n",
    "\n",
    "print(f\"GPUs used:\\t{torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda\",1)\n",
    "print(f\"Device:\\t\\t{device}\")\n",
    "import pytorch_model_summary as tms\n",
    "import random\n",
    "import cv2\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea218d",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"6\">lschemic_CT & SuperResolution</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f2665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"with_condition\": True,\n",
    "    \"inputfolder\": \"../../data/registration_data/registration_DWI/\",\n",
    "    \"batchsize\": 1,\n",
    "    \"epochs\": 10000,\n",
    "    \"input_size\": 128,\n",
    "    \"depth_size\": 64,\n",
    "    \"num_channels\": 64,\n",
    "    \"num_res_blocks\": 1,\n",
    "    \"timesteps\": 250,\n",
    "    \"save_and_sample_every\": 10,\n",
    "    \"model_save_path\": \"../../model/med_ddpm_translation/dwi2ct/\",\n",
    "    \"resume_weight\": \"../../model/med_ddpm/translation/dwi2ct_1.pt\"\n",
    "}\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: \", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b7a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/6479 [15:49<213:22:41, 118.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m a\u001b[38;5;241m=\u001b[39mtensor_A\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     fake_CT \u001b[38;5;241m=\u001b[39m \u001b[43msave_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnii_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../result/generator_sr/temp/dwi2ct.nii.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Clamp to 0~1 range\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     fake_CT[:, :\u001b[38;5;241m5\u001b[39m, :]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     78\u001b[0m     fake_CT[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:, :]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36msave_sample\u001b[0;34m(diffusion, sample_shape, device, temp, condition_tensors)\u001b[0m\n\u001b[1;32m     13\u001b[0m saa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1090000\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batchsize):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:239\u001b[0m, in \u001b[0;36mGaussianDiffusion.sample\u001b[0;34m(self, batch_size, condition_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m depth_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth_size\n\u001b[1;32m    238\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:229\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop\u001b[0;34m(self, shape, condition_tensors)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_condition:\n\u001b[1;32m    228\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((b,), i, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m--> 229\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_sample(img, torch\u001b[38;5;241m.\u001b[39mfull((b,), i, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:214\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[0;34m(self, x, t, condition_tensors, clip_denoised, repeat_noise)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, condition_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, repeat_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    213\u001b[0m     b, \u001b[38;5;241m*\u001b[39m_, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape, x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 214\u001b[0m     model_mean, _, model_log_variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     noise \u001b[38;5;241m=\u001b[39m noise_like(x\u001b[38;5;241m.\u001b[39mshape, device, repeat_noise)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# no noise when t == 0\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:201\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, x, t, clip_denoised, c)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, clip_denoised: \u001b[38;5;28mbool\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_condition:\n\u001b[0;32m--> 201\u001b[0m         x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoise_fn(x, t))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/unet.py:264\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[0;34m(self, x, timesteps, y)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust specify y if and only if the model is class-conditional\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m hs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 264\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed(\u001b[43mtimestep_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_channels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],)\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/modules.py:123\u001b[0m, in \u001b[0;36mtimestep_embedding\u001b[0;34m(timesteps, dim, max_period)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03mCreate sinusoidal timestep embeddings.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m:param timesteps: a 1-D Tensor of N indices, one per batch element.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m:return: an [N x dim] Tensor of positional embeddings.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m half \u001b[38;5;241m=\u001b[39m dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 123\u001b[0m freqs \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_period\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m args \u001b[38;5;241m=\u001b[39m timesteps[:, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m freqs[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    127\u001b[0m embedding \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([th\u001b[38;5;241m.\u001b[39mcos(args), th\u001b[38;5;241m.\u001b[39msin(args)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_sample(diffusion, sample_shape, device,temp, condition_tensors=None):\n",
    "    diffusion.eval()\n",
    "    transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: t.unsqueeze(0))\n",
    "        ])\n",
    "    batchsize=8\n",
    "    # 샘플 생성\n",
    "    condition_tensors1= transform(condition_tensors.get_fdata()).unsqueeze(0).repeat(batchsize, 1, 1, 1, 1)\n",
    "    max_file_size_kb = 3072\n",
    "    file_saved = False\n",
    "    temp1_img=0\n",
    "    saa=1090000\n",
    "    for j in range(1):\n",
    "        samples = diffusion.sample(batch_size=batchsize, condition_tensors=condition_tensors1.to(device))\n",
    "        samples = samples.cpu()\n",
    "        for i in range(batchsize):\n",
    "            temp_img=samples[i][0].numpy()\n",
    "            nifti_img = nib.Nifti1Image(temp_img, affine=np.eye(4))\n",
    "            nib.save(nifti_img, temp)\n",
    "            file_size_kb = os.path.getsize(temp) / 1024\n",
    "            if file_size_kb <= max_file_size_kb:\n",
    "                    return temp_img\n",
    "            else:\n",
    "                if saa> file_size_kb:\n",
    "                    saa=file_size_kb\n",
    "                    temp1_img= temp_img\n",
    "\n",
    "                continue\n",
    "        \n",
    "\n",
    "    return temp1_img\n",
    "\n",
    "def to_numpy_img(tensor):\n",
    "    tensor = tensor.detach().cpu().clamp(0, 1)  # ensure valid range\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "tf=transforms.ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "dwi_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "dwi_sr_model.load_state_dict(torch.load('../../model/ESRGAN/DWI/ckpt_45_checkpoint.pt',map_location=device))\n",
    "ct_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "ct_sr_model.load_state_dict(torch.load('../../model/ESRGAN/CT/ckpt_44_checkpoint.pt',map_location=device))\n",
    "tr_model = create_model(params[\"input_size\"], params[\"num_channels\"], params[\"num_res_blocks\"], in_channels=2, out_channels=1).to(device)\n",
    "diffusion = GaussianDiffusion(\n",
    "    tr_model,\n",
    "    image_size = params[\"input_size\"],\n",
    "    depth_size = params[\"depth_size\"],\n",
    "    timesteps = 250,   # number of steps\n",
    "    loss_type = 'L1', \n",
    "    with_condition=True,\n",
    ").to(device)\n",
    "diffusion.load_state_dict(torch.load(params[\"resume_weight\"],map_location=device))\n",
    "print(\"Model Loaded!\")\n",
    "diffusion.eval()\n",
    "from types import SimpleNamespace\n",
    "\n",
    "data_path='../../result/generator/Ischemic_DWI/'\n",
    "save_path='../../result/generator_sr/'\n",
    "nii_list=glob(data_path+'*.nii.gz')\n",
    "nii_mask_list=[f.replace('/Ischemic_DWI','/Ischemic_mask') for f in nii_list]\n",
    "step=0\n",
    "for i in tqdm(range(len(nii_list))):\n",
    "    nii_img=nib.load(nii_list[i])\n",
    "    nii_img_data=(nii_img.get_fdata()+1.)/2.\n",
    "    nii_img_mask=nib.load(nii_mask_list[i])\n",
    "    nii_img_mask_data=nii_img_mask.get_fdata()\n",
    "    step+=1\n",
    "    folder_name=str(step).zfill(6)\n",
    "    tensor_A=tf(nii_img.get_fdata()).float().to(device)\n",
    "    a=tensor_A.permute(1, 2, 0).unsqueeze(0).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        fake_CT = save_sample(diffusion=diffusion,\n",
    "            sample_shape=(1, diffusion.channels, diffusion.depth_size, diffusion.image_size, diffusion.image_size),\n",
    "            device=device,\n",
    "            condition_tensors=nii_img,\n",
    "            temp='../../result/generator_sr/temp/dwi2ct.nii.gz')  # Clamp to 0~1 range\n",
    "        fake_CT[:, :5, :]=-1\n",
    "        fake_CT[:, -5:, :]=-1\n",
    "        fake_CT[:, :, :5]=-1\n",
    "        fake_CT[:, :, -5:]=-1\n",
    "        fake_CT=(fake_CT+1.)/2\n",
    "\n",
    "        fake_CT=fake_CT.squeeze()\n",
    "    dwi_slide=[]\n",
    "    ct_slide=[]\n",
    "    mask_slide=[]\n",
    "    for j in range(len(nii_img_data)):  # len(nii_img_data)\n",
    "        image=tf(topilimage(nii_img_data[j]).convert('RGB')).float().to(device)\n",
    "        image=image.unsqueeze(0)\n",
    "        ct_image=tf(topilimage(fake_CT[j]).convert('RGB')).float().to(device).unsqueeze(0)\n",
    "        sr_mask=cv2.resize(nii_img_mask_data[j],(256,256))\n",
    "        sr_mask=np.where(sr_mask==2,1,0)*255\n",
    "    \n",
    "        mask_slide.append(sr_mask)\n",
    "        with torch.no_grad():\n",
    "            sr = dwi_sr_model(image)\n",
    "            sr = sr.squeeze(0).cpu().numpy()\n",
    "            sr_ct=F.sigmoid(ct_sr_model(ct_image))\n",
    "            sr_ct = sr_ct.squeeze(0).cpu().numpy()\n",
    "            dwi_slide.append(sr[0])\n",
    "            ct_slide.append(sr_ct[0])\n",
    "        \n",
    "    dwi_slide=np.array(dwi_slide)\n",
    "    # min-max 정규화\n",
    "    dwi_slide = (dwi_slide - dwi_slide.min()) / (dwi_slide.max() - dwi_slide.min())\n",
    "    dwi_slide=dwi_slide*255\n",
    "    dwi_slide = dwi_slide.astype(np.uint8)\n",
    "    ct_slide=np.array(ct_slide)\n",
    "\n",
    "    ct_slide = (ct_slide - ct_slide.min()) / (ct_slide.max() - ct_slide.min())\n",
    "    ct_slide=ct_slide*255\n",
    "    ct_slide = ct_slide.astype(np.uint8)\n",
    "    mask_slide=np.array(mask_slide).astype(np.uint8)\n",
    "    create_dir(save_path+'Ischemic_DWI/'+folder_name)\n",
    "    create_dir(save_path+'Ischemic_CT/'+folder_name)\n",
    "    create_dir(save_path+'Ischemic_mask/'+folder_name)\n",
    "    for j in range(len(nii_img_data)):\n",
    "        Image.fromarray(dwi_slide[j]).save(save_path+'Ischemic_DWI/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(ct_slide[j]).save(save_path+'Ischemic_CT/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(mask_slide[j]).save(save_path+'Ischemic_mask/'+folder_name+'/'+str(j).zfill(6)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afebdd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9892d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_CT.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e2e90",
   "metadata": {},
   "source": [
    "<font size=\"6\">Normal CT & SuperResolution</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "ct_sr_model.load_state_dict(torch.load('../../model/ESRGAN/CT/ckpt_12_checkpoint.pt',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eb95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/4419 [21:09<97:03:26, 79.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m a\u001b[38;5;241m=\u001b[39mtensor_A\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     fake_CT \u001b[38;5;241m=\u001b[39m \u001b[43msave_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnii_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../result/generator_sr/temp/dwi2ct.nii.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Clamp to 0~1 range\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     fake_CT\u001b[38;5;241m=\u001b[39m(fake_CT\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1.\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     78\u001b[0m     fake_CT\u001b[38;5;241m=\u001b[39mfake_CT\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36msave_sample\u001b[0;34m(diffusion, sample_shape, device, temp, condition_tensors)\u001b[0m\n\u001b[1;32m     13\u001b[0m saa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1090000\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batchsize):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:239\u001b[0m, in \u001b[0;36mGaussianDiffusion.sample\u001b[0;34m(self, batch_size, condition_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m depth_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth_size\n\u001b[1;32m    238\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:229\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample_loop\u001b[0;34m(self, shape, condition_tensors)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_condition:\n\u001b[1;32m    228\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((b,), i, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m--> 229\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_sample(img, torch\u001b[38;5;241m.\u001b[39mfull((b,), i, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:214\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_sample\u001b[0;34m(self, x, t, condition_tensors, clip_denoised, repeat_noise)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, condition_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, repeat_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    213\u001b[0m     b, \u001b[38;5;241m*\u001b[39m_, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape, x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 214\u001b[0m     model_mean, _, model_log_variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     noise \u001b[38;5;241m=\u001b[39m noise_like(x\u001b[38;5;241m.\u001b[39mshape, device, repeat_noise)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# no noise when t == 0\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/trainer.py:201\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, x, t, clip_denoised, c)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_mean_variance\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t, clip_denoised: \u001b[38;5;28mbool\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_condition:\n\u001b[0;32m--> 201\u001b[0m         x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_start_from_noise(x, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoise_fn(x, t))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/unet.py:264\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[0;34m(self, x, timesteps, y)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust specify y if and only if the model is class-conditional\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m hs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 264\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed(\u001b[43mtimestep_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_channels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],)\n",
      "File \u001b[0;32m~/gcubme_ai2/Workspace/YS_Lee/stroke synthesis/code/stroke-synthesis/med_ddpm/diffusion_model/modules.py:123\u001b[0m, in \u001b[0;36mtimestep_embedding\u001b[0;34m(timesteps, dim, max_period)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03mCreate sinusoidal timestep embeddings.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m:param timesteps: a 1-D Tensor of N indices, one per batch element.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m:return: an [N x dim] Tensor of positional embeddings.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m half \u001b[38;5;241m=\u001b[39m dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 123\u001b[0m freqs \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_period\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m args \u001b[38;5;241m=\u001b[39m timesteps[:, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m freqs[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    127\u001b[0m embedding \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([th\u001b[38;5;241m.\u001b[39mcos(args), th\u001b[38;5;241m.\u001b[39msin(args)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_sample(diffusion, sample_shape, device,temp, condition_tensors=None):\n",
    "    diffusion.eval()\n",
    "    transform = Compose([\n",
    "    Lambda(lambda t: torch.tensor(t).float()),\n",
    "    Lambda(lambda t: t.unsqueeze(0))\n",
    "        ])\n",
    "    batchsize=5\n",
    "    # 샘플 생성\n",
    "    condition_tensors1= transform(condition_tensors.get_fdata()).unsqueeze(0).repeat(batchsize, 1, 1, 1, 1)\n",
    "    max_file_size_kb = 3072\n",
    "    file_saved = False\n",
    "    temp1_img=0\n",
    "    saa=1090000\n",
    "    for j in range(1):\n",
    "        samples = diffusion.sample(batch_size=batchsize, condition_tensors=condition_tensors1.to(device))\n",
    "        samples = samples.cpu()\n",
    "        for i in range(batchsize):\n",
    "            temp_img=samples[i][0].numpy()\n",
    "            nifti_img = nib.Nifti1Image(temp_img, affine=np.eye(4))\n",
    "            nib.save(nifti_img, temp)\n",
    "            file_size_kb = os.path.getsize(temp) / 1024\n",
    "            if file_size_kb <= max_file_size_kb:\n",
    "                    return temp_img\n",
    "            else:\n",
    "                if saa> file_size_kb:\n",
    "                    saa=file_size_kb\n",
    "                    temp1_img= temp_img\n",
    "                os.remove(temp)  # 너무 크면 삭제하고 재시도\n",
    "                continue\n",
    "        \n",
    "\n",
    "    return temp1_img\n",
    "\n",
    "def to_numpy_img(tensor):\n",
    "    tensor = tensor.detach().cpu().clamp(0, 1)  # ensure valid range\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "tf=transforms.ToTensor()\n",
    "topilimage = torchvision.transforms.ToPILImage()\n",
    "# dwi_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "# dwi_sr_model.load_state_dict(torch.load('../../model/ESRGAN/SWI/ckpt_45_checkpoint.pt',map_location=device))\n",
    "ct_sr_model = RealESRGAN(device, scale=2).model.to(device)\n",
    "ct_sr_model.load_state_dict(torch.load('../../model/ESRGAN/CT/ckpt_12_checkpoint.pt',map_location=device))\n",
    "tr_model = create_model(params[\"input_size\"], params[\"num_channels\"], params[\"num_res_blocks\"], in_channels=2, out_channels=1).to(device)\n",
    "diffusion = GaussianDiffusion(\n",
    "    tr_model,\n",
    "    image_size = params[\"input_size\"],\n",
    "    depth_size = params[\"depth_size\"],\n",
    "    timesteps = 250,   # number of steps\n",
    "    loss_type = 'L1', \n",
    "    with_condition=True,\n",
    ").to(device)\n",
    "diffusion.load_state_dict(torch.load(params[\"resume_weight\"],map_location=device))\n",
    "print(\"Model Loaded!\")\n",
    "diffusion.eval()\n",
    "from types import SimpleNamespace\n",
    "\n",
    "data_path='../../result/generator/Normal_DWI/'\n",
    "save_path='../../result/generator_sr/'\n",
    "nii_list=glob(data_path+'*.nii.gz')\n",
    "nii_mask_list=[f.replace('/Normal_DWI','/Normal_mask') for f in nii_list]\n",
    "step=0\n",
    "for i in tqdm(range(len(nii_list))):\n",
    "    nii_img=nib.load(nii_list[i])\n",
    "    nii_img_data=(nii_img.get_fdata()+1.)/2.\n",
    "    nii_img_mask=nib.load(nii_mask_list[i])\n",
    "    nii_img_mask_data=nii_img_mask.get_fdata()\n",
    "    step+=1\n",
    "    folder_name=str(step).zfill(6)\n",
    "    tensor_A=tf(nii_img.get_fdata()).float().to(device)\n",
    "    a=tensor_A.permute(1, 2, 0).unsqueeze(0).unsqueeze(0)\n",
    "    # with torch.no_grad():\n",
    "    #     fake_CT = save_sample(diffusion=diffusion,\n",
    "    #         sample_shape=(1, diffusion.channels, diffusion.depth_size, diffusion.image_size, diffusion.image_size),\n",
    "    #         device=device,\n",
    "    #         condition_tensors=nii_img,\n",
    "    #         temp='../../result/generator_sr/temp/dwi2ct.nii.gz')  # Clamp to 0~1 range\n",
    "    #     fake_CT=(fake_CT+1.)/2\n",
    "    #     fake_CT[:, :20, :]=0\n",
    "    #     fake_CT[:, -20:, :]=0\n",
    "    #     fake_CT[:, :, :20]=0\n",
    "    #     fake_CT[:, :, -20:]=0\n",
    "    #     fake_CT=fake_CT.squeeze()\n",
    "    dwi_slide=[]\n",
    "    ct_slide=[]\n",
    "    mask_slide=[]\n",
    "    for j in range(len(nii_img_data)):  # len(nii_img_data)\n",
    "        image=tf(topilimage(nii_img_data[j]).convert('RGB')).float().to(device)\n",
    "        image=image.unsqueeze(0)\n",
    "        ct_image=tf(topilimage(fake_CT[j]).convert('RGB')).float().to(device).unsqueeze(0)\n",
    "        sr_mask=cv2.resize(nii_img_mask_data[j],(256,256))\n",
    "        sr_mask=np.where(sr_mask==2,1,0)*255\n",
    "    \n",
    "        mask_slide.append(sr_mask)\n",
    "        with torch.no_grad():\n",
    "            sr = dwi_sr_model(image)\n",
    "            sr = sr.squeeze(0).cpu().numpy()\n",
    "            sr_ct=ct_sr_model(ct_image)\n",
    "            sr_ct = sr_ct.squeeze(0).cpu().numpy()\n",
    "            dwi_slide.append(sr[0])\n",
    "            ct_slide.append(sr_ct[0])\n",
    "        \n",
    "    dwi_slide=np.array(dwi_slide)\n",
    "    # min-max 정규화\n",
    "    dwi_slide = (dwi_slide - dwi_slide.min()) / (dwi_slide.max() - dwi_slide.min())\n",
    "    dwi_slide=dwi_slide*255\n",
    "    dwi_slide = dwi_slide.astype(np.uint8)\n",
    "    ct_slide=np.array(ct_slide)\n",
    "\n",
    "    ct_slide = (ct_slide - ct_slide.min()) / (ct_slide.max() - ct_slide.min())\n",
    "    ct_slide=ct_slide*255\n",
    "    ct_slide = ct_slide.astype(np.uint8)\n",
    "    mask_slide=np.array(mask_slide).astype(np.uint8)\n",
    "    create_dir(save_path+'Normal_DWI/'+folder_name)\n",
    "    create_dir(save_path+'Normal_CT/'+folder_name)\n",
    "    create_dir(save_path+'Normal_mask/'+folder_name)\n",
    "    for j in range(len(nii_img_data)):\n",
    "        Image.fromarray(dwi_slide[j]).save(save_path+'Normal_DWI/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(ct_slide[j]).save(save_path+'Normal_CT/'+folder_name+'/'+str(j).zfill(6)+'.png')\n",
    "        Image.fromarray(mask_slide[j]).save(save_path+'Normal_mask/'+folder_name+'/'+str(j).zfill(6)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c295c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(tr_model.netG_A, input_size=(1, 1, 64, 128, 128), device=opt.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
